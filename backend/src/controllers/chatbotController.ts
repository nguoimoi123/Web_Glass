import dotenv from "dotenv";
import path from "path";
import { Request, Response } from "express";
import OpenAI from "openai";

// ‚úÖ N·∫°p file .env
dotenv.config({ path: path.resolve(__dirname, "../../.env") });

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// ‚úÖ M√¥ t·∫£ vai tr√≤ c·ªßa chatbot
const SYSTEM_PROMPT = `B·∫°n l√† m·ªôt tr·ª£ l√Ω AI th√¢n thi·ªán v√† hi·ªÉu bi·∫øt cho VisionLuxe ‚Äî c·ª≠a h√†ng m·∫Øt k√≠nh cao c·∫•p. 

V·ªÅ VisionLuxe:
- B√°n c√°c lo·∫°i m·∫Øt k√≠nh th·ªùi trang, k√≠nh m√°t, k√≠nh c·∫≠n, v√† ph·ª• ki·ªán
- S·∫£n ph·∫©m k·∫øt h·ª£p gi·ªØa phong c√°ch v√† t√≠nh nƒÉng
- Mi·ªÖn ph√≠ v·∫≠n chuy·ªÉn cho ƒë∆°n h√†ng tr√™n 100$
- Ch√≠nh s√°ch ƒë·ªïi tr·∫£ trong v√≤ng 30 ng√†y
- C√≥ t√≠nh nƒÉng th·ª≠ k√≠nh ·∫£o (virtual try-on)

Vai tr√≤ c·ªßa b·∫°n:
- Gi√∫p kh√°ch h√†ng ch·ªçn lo·∫°i k√≠nh ph√π h·ª£p nh·∫•t
- Gi·∫£i ƒë√°p th·∫Øc m·∫Øc v·ªÅ s·∫£n ph·∫©m, k√≠ch th∆∞·ªõc, ch·∫•t li·ªáu, v√† c√°ch b·∫£o qu·∫£n
- ƒê∆∞a ra g·ª£i √Ω phong c√°ch d·ª±a tr√™n h√¨nh d·∫°ng khu√¥n m·∫∑t v√† s·ªü th√≠ch
- H·ªó tr·ª£ tra c·ª©u ƒë∆°n h√†ng, ƒë·ªïi tr·∫£, v·∫≠n chuy·ªÉn
- Lu√¥n th√¢n thi·ªán, chuy√™n nghi·ªáp, v√† am hi·ªÉu
- N·∫øu b·ªã h·ªèi v·ªÅ s·∫£n ph·∫©m kh√¥ng c√≥ trong ng·ªØ c·∫£nh, h√£y khuy√™n kh√°ch truy c·∫≠p trang Shop

Gi·ªØ c√¢u tr·∫£ l·ªùi ng·∫Øn g·ªçn (2‚Äì3 c√¢u), tr·ª´ khi ng∆∞·ªùi d√πng y√™u c·∫ßu chi ti·∫øt h∆°n.`;

// ‚úÖ H√†m ch√≠nh x·ª≠ l√Ω h·ªôi tho·∫°i
export const chatWithBot = async (req: Request, res: Response) => {
  try {
    const { message, conversationHistory } = req.body;

    // Ki·ªÉm tra h·ª£p l·ªá
    if (!message || typeof message !== "string") {
      return res
        .status(400)
        .json({ error: "C·∫ßn c√≥ tr∆∞·ªùng 'message' ki·ªÉu chu·ªói (string)." });
    }

    // ‚úÖ T·∫°o danh s√°ch tin nh·∫Øn g·ª≠i l√™n API
    const messages: any[] = [{ role: "system", content: SYSTEM_PROMPT }];

    // ‚úÖ Th√™m l·ªãch s·ª≠ h·ªôi tho·∫°i g·∫ßn nh·∫•t (t·ªëi ƒëa 10 tin)
    if (conversationHistory && Array.isArray(conversationHistory)) {
      const recentHistory = conversationHistory
        .slice(-10)
        .filter((m) => m.role && m.content);
      messages.push(...recentHistory);
    }

    // ‚úÖ Th√™m tin nh·∫Øn hi·ªán t·∫°i c·ªßa ng∆∞·ªùi d√πng
    messages.push({ role: "user", content: message });

    console.log("üó®Ô∏è G·ª≠i y√™u c·∫ßu t·ªõi OpenAI v·ªõi", messages.length, "tin nh·∫Øn...");

    // ‚úÖ G·ªçi OpenAI API (model hi·ªán t·∫°i kh√¥ng h·ªó tr·ª£ temperature t√πy ch·ªânh)
    const response = await openai.chat.completions.create({
      model: "gpt-4o", // Ho·∫∑c "gpt-4o-mini" ƒë·ªÉ ti·∫øt ki·ªám chi ph√≠
      messages,
      max_completion_tokens: 800,
    });

    const botMessage =
      response.choices?.[0]?.message?.content?.trim() || "(Kh√¥ng c√≥ ph·∫£n h·ªìi)";


    // ‚úÖ G·ª≠i ph·∫£n h·ªìi v·ªÅ frontend
    res.json({
      message: botMessage,
      conversationId: Date.now().toString(),
    });
  } catch (error: any) {
    res.status(500).json({
      error: "Kh√¥ng th·ªÉ l·∫•y ph·∫£n h·ªìi t·ª´ chatbot",
      details: error.response?.data || error.message,
    });
  }
};
